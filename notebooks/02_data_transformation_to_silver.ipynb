{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8deb2161-9349-4fb6-9c9a-9e6cf3400dad",
   "metadata": {},
   "source": [
    "# notebook/02_data_transformation_to_silver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c215dea2-5f69-410f-a3a4-55af185f16ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys \n",
    "import logging\n",
    "\n",
    "# Caminho para a raiz do seu projeto\n",
    "project_root = os.path.abspath(\"..\")  # Sobe um nível de pasta a partir de 'notebooks'\n",
    "\n",
    "# Adiciona o caminho ao sys.path\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from src.utils import functions as F\n",
    "from config.configs import *\n",
    "from config.spark_session import create_spark_session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32754fc5-9e05-4806-80dc-c3cd76d318d7",
   "metadata": {},
   "source": [
    "## Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8857a0d9-35c5-4985-baa6-e6454f731c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = create_spark_session(HOST_ADDRESS, MINIO_ACCESS_KEY, MINIO_SECRET_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14b249c-9cea-4887-bece-97dd34178061",
   "metadata": {},
   "source": [
    "## Log configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafffb8e-9922-4530-8d18-2923fca5a99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "logging.info(\"Starting convertions from Bronze(Delta) to Silver(Delta) - COVID19...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c70a15-fc8d-4688-9013-5a7652d48817",
   "metadata": {},
   "source": [
    "## Path configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9234e5e2-68b7-4f4f-ab59-bfdf6f3ea075",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_prefix_layer_name = prefix_layer_name['1']  # bronze layer\n",
    "input_path = lake_path['bronze']\n",
    "\n",
    "output_prefix_layer_name = prefix_layer_name['2']  # silver layer\n",
    "storage_output = lake_path['silver']\n",
    "output_tabela_name = tabela_name['0']  # nivel agregação\n",
    "\n",
    "output_full_name = f\"{storage_output}{output_prefix_layer_name}{output_tabela_name}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16aeaf2-7592-470b-954c-cf1488eedc8e",
   "metadata": {},
   "source": [
    "## Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ace4fd8-5803-4ef8-85c3-ebcb82398ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/18 11:30:28 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n",
      "24/11/18 11:30:31 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                2024-11-18 11:30:42,956 - INFO - Query 'SELECT\n",
      "\tlocation_key, country_name, date,\n",
      "    population, new_confirmed, new_deceased, new_recovered,\n",
      "    cumulative_confirmed, cumulative_deceased, cumulative_recovered,\n",
      "    new_persons_vaccinated, cumulative_persons_vaccinated,\n",
      "    new_hospitalized_patients, cumulative_hospitalized_patients,\n",
      "    mobility_retail_and_recreation, aggregation_level\n",
      "FROM\n",
      "    delta.`s3a://bronze/covid19/bronze_covid19` \n",
      "WHERE \n",
      "    date IS NOT NULL AND \n",
      "    location_key IS NOT NULL\n",
      "    \n",
      "    ' successfully processed and saved to s3a://silver/covid19/silver_covid19\n",
      "2024-11-18 11:30:42,956 - INFO - Process to silver completed!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    for table_name, query_input in tables_silver.items():\n",
    "        table_name = F.convert_table_name(table_name)\n",
    "\n",
    "        # Obter a consulta para o carregamento do arquivo\n",
    "        query_input = F.get_query(table_name, input_path, input_prefix_layer_name, output_tabela_name, tables_silver)\n",
    "        \n",
    "        # Definir o caminho de saída\n",
    "        storage_output = f'{output_full_name}'\n",
    "\n",
    "        # Chamar a função process_table para processar e gravar os dados\n",
    "        F.process_table(spark, query_input, output_full_name)\n",
    "    \n",
    "    logging.info(\"Process to silver completed!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logging.error(f'Error processing table: {str(e)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
